{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given Data Loader in Siamese_Sample folder\n",
    "# Train Libraries\n",
    "from __future__ import print_function\n",
    "import argparse, random, copy\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as T\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "# from dataloader import train_test_split, FingerprintDataset, ImageTransform\n",
    "# from model import SiameseNetwork\n",
    "import json\n",
    "\n",
    "\n",
    "# Model Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "\n",
    "# Dataloader libraries\n",
    "import os\n",
    "import random\n",
    "import albumentations\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, text=None):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "        \n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()    \n",
    "\n",
    "# Plotting data\n",
    "def show_plot(iteration,loss):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_dist = F.pairwise_distance(output1, output2, keepdim=True)\n",
    "\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_dist, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_dist, min=0.0), 2))\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, criterion):\n",
    "    counter = []\n",
    "    loss_history = []\n",
    "    iteration_number = 0\n",
    "\n",
    "    for i, (img0, img1, label, _, _) in enumerate(train_loader, 0):\n",
    "\n",
    "        # Send the images and labels to CUDA\n",
    "        img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Pass in the two images into the network and obtain two outputs\n",
    "        output1, output2 = model(img0, img1)\n",
    "\n",
    "        # Pass the outputs of the networks and label into the loss function\n",
    "        loss_contrastive = criterion(output1, output2, label)\n",
    "\n",
    "        # Calculate the backpropagation\n",
    "        loss_contrastive.backward()\n",
    "\n",
    "        # Optimize\n",
    "        optimizer.step()\n",
    "\n",
    "        # Every 10 batches print out the loss\n",
    "        if i % 10 == 0 :\n",
    "            print(f\"Epoch number {epoch}\\n Current loss {loss_contrastive.item()}\\n\")\n",
    "            iteration_number += 10\n",
    "            counter.append(iteration_number)\n",
    "            print(iteration_number)\n",
    "            loss_history.append(loss_contrastive.item())\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "\t\t\t\tepoch, i * len(img0), len(train_loader.dataset),\n",
    "\t\t\t\t100. * i / len(train_loader), loss_contrastive.item()))\n",
    "        # if iteration_number==:\n",
    "        #     show_plot(counter, loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The FingerPrintDataset used to load into pytorch dataloader\n",
    "class FingerprintDataset(Dataset):\n",
    "  def __init__(self, data_nums, data_list, transform=None, transAug=None):\n",
    "    self.data_nums = data_nums\n",
    "    self.data_list = data_list\n",
    "    self.transform = transform\n",
    "    self.transAug = transAug\n",
    "    \n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "  \n",
    "    real_dir = '../../SOCOFingBMP/Real'\n",
    "    real_imgs = os.listdir(real_dir)\n",
    "\n",
    "    # img will be a case from altered image\n",
    "    img = self.data_list[idx]\n",
    "    # find a corresponding name that can be used for identifying the real image\n",
    "    img_name_real = img[img.rfind('/')+1:img.rfind('_')] + '.BMP'\n",
    "    \n",
    "    # This will set probability for creating matching or non-matching case at 50%\n",
    "    print_match = idx % 2 == 0\n",
    "\n",
    "    # This will set probability for applying augmentation at 50%\n",
    "    apply_aug = random.randint(0,1)\n",
    "    \n",
    "    # print_match : 0 means non-matching fingerprints\n",
    "    # print_match : 1 means matching fingerprints\n",
    "    if print_match : # Define the directory for which we will find the matching real case (same individual)\n",
    "      real_img_dir = os.path.join(real_dir, img_name_real)\n",
    "    else :\n",
    "      while True: # Define the directory for which we will find the non-matching real case (different individual)\n",
    "        real_img_num = random.choice(self.data_nums)-1 \n",
    "        img_name_real_unmatch = real_imgs[real_img_num]\n",
    "        \n",
    "        if img_name_real != img_name_real_unmatch:\n",
    "          real_img_dir = os.path.join(real_dir, img_name_real_unmatch)\n",
    "          break\n",
    "\n",
    "    real_directory = real_img_dir\n",
    "    # print(real_directory)\n",
    "    altered_directory = img\n",
    "    # print(altered_directory)\n",
    "    real = Image.open(real_img_dir).convert(\"L\")\n",
    "    altered = Image.open(img).convert(\"L\")\n",
    "    \n",
    "    real = self.transform(real)\n",
    "\n",
    "    if self.transAug is None :\n",
    "      altered = self.transform(altered)\n",
    "    else : \n",
    "      if apply_aug :\n",
    "        altered_np = np.array(altered)\n",
    "        altered_augmented = self.transAug(altered_np)\n",
    "        altered = Image.fromarray(altered_augmented['image'])\n",
    "        altered = self.transform(altered)\n",
    "      else : \n",
    "        altered = self.transform(altered)\n",
    "    \n",
    "    # label = torch.from_numpy(np.array([int(print_match)], dtype=np.long))\n",
    "    label = torch.tensor(print_match, dtype=torch.float)\n",
    "    # label = print_match\n",
    "    # pairset = {\"real\": real, \"altered\": altered, \"label\": torch.from_numpy(np.array([int(print_match)], dtype=np.float32))}\n",
    "    \n",
    "    # return pairset\n",
    "    return real, altered, label, real_directory, altered_directory\n",
    "\n",
    "  def __len__(self):\n",
    "    length = len(self.data_list)\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(base_dir, train_ratio, num_people = 600, randomize = True, tests = None):\n",
    "\n",
    "  # Splitting the train & test data according to the 'train_ratio' (ex. 0.9 : 0.1) \n",
    "  train_size = num_people * train_ratio\n",
    "  test_size = num_people - train_size\n",
    "\n",
    "  # Setting train_nums to be a list composed of 1 ~ 600\n",
    "  train_nums = [i+1 for i in range(0,num_people)]\n",
    "  # Setting test_nums to be a list composed of 600 zeros ([0,0,.....,0])\n",
    "  test_nums = [0 for i in range(0, num_people)]\n",
    "\n",
    "  train_list = []\n",
    "  test_list = []\n",
    "\n",
    "  altered_root = os.path.join(base_dir, \"Altered\")\n",
    "  altered_list = [\"Altered-Easy\", \"Altered-Medium\", \"Altered-Hard\"]\n",
    "\n",
    "  test_check = []\n",
    "\n",
    "  # Randomly select people who will be used as test subjects\n",
    "  if randomize :\n",
    "    while len(test_check) < test_size:\n",
    "      test = random.randint(1,num_people)\n",
    "      if test not in test_check :\n",
    "        test_check.append(test)\n",
    "        test_nums[test-1] = test\n",
    "    \n",
    "    for i in range(0, len(train_nums)):\n",
    "      train_nums[i] = train_nums[i]-test_nums[i]\n",
    "\n",
    "    train_nums = set(train_nums)\n",
    "    train_nums.remove(0)\n",
    "    train_nums = list(train_nums)\n",
    "\n",
    "    test_nums = set(test_nums)\n",
    "    test_nums.remove(0)\n",
    "    test_nums = list(test_nums)\n",
    "\n",
    "    print(\"Num Train Data : \",len(train_nums))\n",
    "    print(\"Num Test Data : \", len(test_nums))\n",
    "  # If we pre-select test subjects, then just remove these from the train subjects\n",
    "  # train subjects will initially contain all individuals (1 ~ 600)\n",
    "  else :\n",
    "    test_nums = tests\n",
    "    for i in range(0, len(test_nums)):\n",
    "      if test_nums[i] in train_nums:\n",
    "        train_nums.remove(test_nums[i])\n",
    "  \n",
    "  # Let's go through the altered images and organize them depending on \n",
    "  # whether they can be used for training or testing of the model\n",
    "  for altered in altered_list : \n",
    "    altered_dir = os.path.join(altered_root, altered)\n",
    "    altered_imgs = os.listdir(altered_dir)\n",
    "    \n",
    "    for img in altered_imgs :\n",
    "      person_num = int(img[:img.find('__')])\n",
    "      if person_num in test_nums :\n",
    "        test_img_path = os.path.join(altered_dir, img)\n",
    "        test_list.append(test_img_path)\n",
    "      else:\n",
    "        train_img_path = os.path.join(altered_dir, img)\n",
    "        train_list.append(train_img_path)\n",
    "\n",
    "  # train_list & test_list are made of altered images\n",
    "  return train_nums, train_list, test_nums, test_list\n",
    "\n",
    "class ImageTransform():\n",
    "  def __init__(self, mean, std):\n",
    "    self.data_transform = transforms.Compose([\n",
    "        transforms.Resize((100, 100)),\n",
    "        # transforms.Resize((95, 95)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ])\n",
    "\n",
    "  def __call__(self, img):\n",
    "    # print(type(img))\n",
    "    return self.data_transform(img)\n",
    "      \n",
    "class ImageAugTransform_train():\n",
    "  def __init__(self, mean, std):\n",
    "    self.albumentations_transform_oneof = albumentations.Compose([\n",
    "                                                                  albumentations.Resize(100, 100),\n",
    "                                                                  albumentations.Normalize(mean=mean, std=std, max_pixel_value=255),\n",
    "                                                                  albumentations.OneOf([\n",
    "                                                                                        albumentations.HorizontalFlip(p=0.5),\n",
    "                                                                                        albumentations.RandomRotate90(p=0.5)\n",
    "                                                                                        ], p=0.5),\n",
    "                                                                  albumentations.OneOf([\n",
    "                                                                  albumentations.GaussNoise(p=0.5)\n",
    "                                                                  ], p=0.5),\n",
    "                                                                  albumentations.RandomBrightness(limit=0.2, always_apply=False, p=0.5)\n",
    "                                                                  ])\n",
    "\n",
    "  def __call__(self, img):\n",
    "      return self.albumentations_transform_oneof(image=img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ORIGINAL SIAMESE NETWORK \n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "\n",
    "        self.resnet = torchvision.models.resnet18(pretrained=False)\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.fc_in_features = self.resnet.fc.in_features\n",
    "        self.resnet = torch.nn.Sequential(*(list(self.resnet.children())[:-1]))\n",
    "\n",
    "        # convolutional neural network\n",
    "        # self.cnn1 = nn.Sequential(\n",
    "        #     nn.Conv2d(1, 96, kernel_size=11, stride=4),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.MaxPool2d(3, stride=2),\n",
    "\n",
    "        #     nn.Conv2d(96, 256, kernel_size=5, stride=1),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "        #     nn.Conv2d(256, 384, kernel_size=3, stride=1),\n",
    "        #     nn.ReLU(inplace=True)\n",
    "        # )\n",
    "\n",
    "        # fully connected layers\n",
    "        self.fc1 = nn.Sequential(\n",
    "            # nn.Linear(512, 1024),\n",
    "            # nn.ReLU(inplace=True),\n",
    "\n",
    "            # nn.Linear(1024, 256), \n",
    "            # nn.ReLU(inplace=True),\n",
    "\n",
    "            # nn.Linear(256, 2)\n",
    "            nn.Linear(self.fc_in_features, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.resnet.apply(self.init_weights)\n",
    "        self.fc1.apply(self.init_weights)\n",
    "\n",
    "\n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "    \n",
    "    def forward_once(self, x):\n",
    "        output = self.resnet(x)\n",
    "        # output = self.cnn1(output)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "    \n",
    "    def forward(self, input1, input2):\n",
    "        # output1 = self.forward_once(input1)\n",
    "        # output2 = self.forward_once(input2)\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "\n",
    "        # concatenate both images' features\n",
    "        # output = torch.cat((output1, output2), 1)\n",
    "\n",
    "        # pass the concatenation to the linear layers\n",
    "        # output = self.fc1(output)\n",
    "\n",
    "        # pass the out of the linear layers to sigmoid layer\n",
    "        # output = self.sigmoid(output)\n",
    "        \n",
    "        # return output\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    # we aren't using `TripletLoss` as the MNIST dataset is simple, so `BCELoss` can do the trick.\n",
    "    criterion = ContrastiveLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (images_1, images_2, targets, real_addr, altered_addr) in test_loader:\n",
    "            images_1, images_2, targets = images_1.to(device), images_2.to(device), targets.to(device)\n",
    "            output1, output2 = model(images_1, images_2)\n",
    "\n",
    "            # Calculate the distance between output1 and output2\n",
    "            euclidean_dist = F.pairwise_distance(output1, output2)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = criterion(output1, output2, targets)\n",
    "\n",
    "            test_loss += loss.item()  # Sum up batch loss\n",
    "\n",
    "            # Convert distances to binary predictions\n",
    "            pred = (euclidean_dist > 0.5).float()\n",
    "\n",
    "            # Calculate the number of correct predictions\n",
    "            correct += pred.eq(targets).sum().item()\n",
    "            # test_loss += criterion(output1, output2, targets).sum().item()  # sum up batch loss\n",
    "            # outputs = (output1+output2)/2.0\n",
    "            # ones = torch.ones(outputs.shape[0],).to(device)\n",
    "            # zeros = torch.zeros(outputs.shape[0],).to(device)\n",
    "            # pred = torch.where(outputs > 0.5, ones, zeros)  # get the index of the max log-probability\n",
    "            # correct += pred.eq(targets.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    # for the 1st epoch, the average loss is 0.0001 and the accuracy 97-98%\n",
    "    # using default settings. After completing the 10th epoch, the average\n",
    "    # loss is 0.0000 and the accuracy 99.5-100% using default settings.\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Train Data :  420\n",
      "Num Test Data :  180\n",
      "Train List Length :  34401\n",
      "Test List Length :  14869\n",
      "cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kiss2023/anaconda3/envs/fingerprint_new/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/kiss2023/anaconda3/envs/fingerprint_new/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56706/1468529929.py:45: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(m.weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 0\n",
      " Current loss 1.2771819829940796\n",
      "\n",
      "10\n",
      "Train Epoch: 0 [0/34401 (0%)]\tLoss: 1.277182\n",
      "Epoch number 0\n",
      " Current loss 2.279956817626953\n",
      "\n",
      "20\n",
      "Train Epoch: 0 [1280/34401 (4%)]\tLoss: 2.279957\n",
      "Epoch number 0\n",
      " Current loss 7.030306816101074\n",
      "\n",
      "30\n",
      "Train Epoch: 0 [2560/34401 (7%)]\tLoss: 7.030307\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[150], line 155\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy: \u001b[39m\u001b[39m\"\u001b[39m, success\u001b[39m/\u001b[39mtotal)\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 155\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[150], line 113\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m    112\u001b[0m     \u001b[39mprint\u001b[39m(epoch)\n\u001b[0;32m--> 113\u001b[0m     train(model, device, train_loader, optimizer, epoch, criterion)\n\u001b[1;32m    114\u001b[0m     \u001b[39m# test(model, device, test_loader)\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     scheduler\u001b[39m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[145], line 6\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch, criterion)\u001b[0m\n\u001b[1;32m      3\u001b[0m loss_history \u001b[39m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m iteration_number \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfor\u001b[39;00m i, (img0, img1, label, _, _) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader, \u001b[39m0\u001b[39m):\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m     \u001b[39m# Send the images and labels to CUDA\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     img0, img1, label \u001b[39m=\u001b[39m img0\u001b[39m.\u001b[39mcuda(), img1\u001b[39m.\u001b[39mcuda(), label\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     11\u001b[0m     \u001b[39m# Zero the gradients\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fingerprint_new/lib/python3.9/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/fingerprint_new/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1330\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1329\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1330\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1331\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1332\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1333\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fingerprint_new/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1286\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1284\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m   1285\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[0;32m-> 1286\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1287\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1288\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/fingerprint_new/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1134\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1122\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1135\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1136\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1137\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fingerprint_new/lib/python3.9/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[39mif\u001b[39;00m remaining \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait(remaining)\n\u001b[1;32m    181\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_full\u001b[39m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/anaconda3/envs/fingerprint_new/lib/python3.9/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[1;32m    317\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    batch_size = 128\n",
    "    # parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "    #                     help='input batch size for testing (default: 1000)')\n",
    "    test_batch_size = 1000\n",
    "    # parser.add_argument('--epochs', type=int, default=14, metavar='N',\n",
    "    #                     help='number of epochs to train (default: 14)')\n",
    "    epochs = 3\n",
    "    # parser.add_argument('--lr', type=float, default=1.0, metavar='LR',\n",
    "    #                     help='learning rate (default: 1.0)')\n",
    "    lr = 0.01\n",
    "    # parser.add_argument('--gamma', type=float, default=0.7, metavar='M',\n",
    "    #                     help='Learning rate step gamma (default: 0.7)')\n",
    "    gamma = 0.7\n",
    "    # parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "    #                     help='disables CUDA training')\n",
    "    no_cuda = False\n",
    "    # parser.add_argument('--no-mps', action='store_true', default=False,\n",
    "    #                     help='disables macOS GPU training')\n",
    "    no_mps = False\n",
    "    # parser.add_argument('--dry-run', action='store_true', default=False,\n",
    "    #                     help='quickly check a single pass')\n",
    "    dry_run = False\n",
    "    # parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "    #                     help='random seed (default: 1)')\n",
    "    seed = 1\n",
    "    # parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "    #                     help='how many batches to wait before logging training status')\n",
    "    log_interval = 10\n",
    "    # parser.add_argument('--save-model', action='store_true', default=False,\n",
    "    #                     help='For Saving the current Model')\n",
    "    save_model = True\n",
    "    # args = parser.parse_args()\n",
    "    cuda_num = 1\n",
    "    use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "    torch.cuda.set_device(cuda_num)\n",
    "    torch.manual_seed(seed)\n",
    "    device = torch.device(\"cuda:{}\".format(cuda_num) if torch.cuda.is_available() else \"cpu\")\n",
    "    # device = torch.device(\"cpu\")\n",
    "    train_kwargs = {'batch_size': batch_size}\n",
    "    test_kwargs = {'batch_size': test_batch_size}\n",
    "    if use_cuda:\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "\n",
    "    mean = (0.5,) #q1\n",
    "    std = (0.5,)\n",
    "\n",
    "    # device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # torch.cuda.set_device(2)\n",
    "    # Change the directory to where SOCOFing is located. \n",
    "    # Direcotories should look as the following\n",
    "    # SOCOFing\n",
    "    # -- Altered\n",
    "    #    -- ...\n",
    "    # -- Real\n",
    "    #    -- ...\n",
    "    base_dir = '../../SOCOFingBMP/'\n",
    "\n",
    "    nums = {}\n",
    "    train_nums, train_list, test_nums, test_list = train_test_split(base_dir, 0.7)\n",
    "    print(\"Train List Length : \", len(train_list))\n",
    "    print(\"Test List Length : \", len(test_list))\n",
    "\n",
    "    nums['train'] = train_nums\n",
    "    nums['test'] = test_nums\n",
    "    \n",
    "    # state_dict save file name : siamese_network_train%_test%_lr.pt\n",
    "    outpath = 'train_test_split_7_3_1.json'\n",
    "\n",
    "    with open(outpath, 'w') as f:\n",
    "        json.dump(nums, f)\n",
    "\n",
    "    print(device)\n",
    "    train_dataset = FingerprintDataset(train_nums, train_list,transform=ImageTransform(mean,std), transAug=None)\n",
    "    test_dataset = FingerprintDataset(test_nums, test_list, transform=ImageTransform(mean,std))\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,**train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, **test_kwargs)\n",
    "\n",
    "    model = SiameseNetwork().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "            \n",
    "    criterion = ContrastiveLoss()\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "\n",
    "    # Create a simple dataloader just for simple visualization\n",
    "    # vis_dataloader = DataLoader(trainset,\n",
    "    #                         shuffle=True,\n",
    "    #                         num_workers=2,\n",
    "    #                         batch_size=8)\n",
    "\n",
    "    # # Extract one batch\n",
    "    # example_batch = next(iter(vis_dataloader))\n",
    "\n",
    "    # # Example batch is a list containing 2x8 images, indexes 0 and 1, an also the label\n",
    "    # # If the label is 1, it means that it is not the same person, label is 0, same person in both images\n",
    "    # concatenated = torch.cat((example_batch[0], example_batch[1]),0)\n",
    "\n",
    "    # imshow(torchvision.utils.make_grid(concatenated))\n",
    "    # print(example_batch[2].numpy().reshape(-1))\n",
    "\n",
    "    #######################################################\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(epoch)\n",
    "        train(model, device, train_loader, optimizer, epoch, criterion)\n",
    "        # test(model, device, test_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "\n",
    "    # # Locate the test dataset and load it into the SiameseNetworkDataset\n",
    "    siamese_dataset = FingerprintDataset(test_nums, test_list, transform=ImageTransform(mean,std))\n",
    "    test_dataloader = DataLoader(siamese_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    # Grab one image that we are going to test\n",
    "    dataiter = iter(test_dataloader)\n",
    "    x0, x1, label, _, _ = next(dataiter)\n",
    "\n",
    "    while label!=0:\n",
    "        x0, x1, label, _, _ = next(dataiter)\n",
    "        \n",
    "    first = 0\n",
    "    success = 0\n",
    "    total = 0\n",
    "    for i in range(1000):\n",
    "        # Iterate over 5 images and test them with the first image (x0)\n",
    "        if first>0:\n",
    "            x0, x1, label, _, _ = next(dataiter)\n",
    "        first+=1\n",
    "        # Concatenate the two images together\n",
    "        concatenated = torch.cat((x0, x1), 0)\n",
    "        print(concatenated.size())\n",
    "        print(\"label:\", label)\n",
    "        output1, output2 = model(x0.cuda(), x1.cuda())\n",
    "        print(\"Outputs: \", output1, output2)\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)[0]\n",
    "        print(\"euclidean dist:\", euclidean_distance)\n",
    "        # imshow(torchvision.utils.make_grid(concatenated), f'Dissimilarity: {euclidean_distance.item():.2f}')\n",
    "        if (euclidean_distance.item() < 0.75 and label==1) or (euclidean_distance.item() >= 0.75 and label==0):\n",
    "            success+=1\n",
    "        total+=1\n",
    "    \n",
    "\n",
    "    print(\"Accuracy: \", success/total)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tasks\n",
    "# 0. Figure out why the resnet18 structure is not learning properly (test to at least 50 to 100 epochs)\n",
    "# 0.5. Tweak code to output accuracy of test cases of each level (easy, med, hard) not altogether bc right now it is randomized \n",
    "# 1. Change Structures: Test Contrastive Loss with Resnet 50 structures \n",
    "# 2. Change Structures: Test BCE Loss with Resnet 50 structures\n",
    "# 3. Learn about the matrix calculations in CNNs\n",
    "# 4. Learn about vision transformers \n",
    "# 5. Try different optimizers: ADAM, AdaDelta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fingerprint_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
