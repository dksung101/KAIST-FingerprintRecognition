{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Train Data :  420\n",
      "Num Test Data :  180\n",
      "Train List Length :  34496\n",
      "Test List Length :  14774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32075/1014197067.py:225: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(m.weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/34496 (0%)]\tLoss: 0.798725\n",
      "Train Epoch: 1 [1280/34496 (4%)]\tLoss: 0.665253\n",
      "Train Epoch: 1 [2560/34496 (7%)]\tLoss: 0.545991\n",
      "Train Epoch: 1 [3840/34496 (11%)]\tLoss: 0.591728\n",
      "Train Epoch: 1 [5120/34496 (15%)]\tLoss: 0.310976\n",
      "Train Epoch: 1 [6400/34496 (19%)]\tLoss: 0.249553\n",
      "Train Epoch: 1 [7680/34496 (22%)]\tLoss: 0.348423\n",
      "Train Epoch: 1 [8960/34496 (26%)]\tLoss: 0.261792\n",
      "Train Epoch: 1 [10240/34496 (30%)]\tLoss: 0.148376\n",
      "Train Epoch: 1 [11520/34496 (33%)]\tLoss: 0.226249\n",
      "Train Epoch: 1 [12800/34496 (37%)]\tLoss: 0.117022\n",
      "Train Epoch: 1 [14080/34496 (41%)]\tLoss: 0.168114\n",
      "Train Epoch: 1 [15360/34496 (44%)]\tLoss: 0.159113\n",
      "Train Epoch: 1 [16640/34496 (48%)]\tLoss: 0.152216\n",
      "Train Epoch: 1 [17920/34496 (52%)]\tLoss: 0.201050\n",
      "Train Epoch: 1 [19200/34496 (56%)]\tLoss: 0.109179\n",
      "Train Epoch: 1 [20480/34496 (59%)]\tLoss: 0.138588\n",
      "Train Epoch: 1 [21760/34496 (63%)]\tLoss: 0.111039\n",
      "Train Epoch: 1 [23040/34496 (67%)]\tLoss: 0.135633\n",
      "Train Epoch: 1 [24320/34496 (70%)]\tLoss: 0.084352\n",
      "Train Epoch: 1 [25600/34496 (74%)]\tLoss: 0.048783\n",
      "Train Epoch: 1 [26880/34496 (78%)]\tLoss: 0.085161\n",
      "Train Epoch: 1 [28160/34496 (81%)]\tLoss: 0.094140\n",
      "Train Epoch: 1 [29440/34496 (85%)]\tLoss: 0.078146\n",
      "Train Epoch: 1 [30720/34496 (89%)]\tLoss: 0.116909\n",
      "Train Epoch: 1 [32000/34496 (93%)]\tLoss: 0.081828\n",
      "Train Epoch: 1 [33280/34496 (96%)]\tLoss: 0.121690\n",
      "alteredaddr length:  1000\n",
      "alteredaddr length:  1000\n",
      "alteredaddr length:  1000\n",
      "alteredaddr length:  1000\n",
      "alteredaddr length:  1000\n",
      "alteredaddr length:  1000\n",
      "alteredaddr length:  1000\n",
      "alteredaddr length:  1000\n",
      "alteredaddr length:  1000\n",
      "alteredaddr length:  1000\n",
      "alteredaddr length:  1000\n",
      "alteredaddr length:  1000\n",
      "alteredaddr length:  1000\n",
      "alteredaddr length:  1000\n",
      "alteredaddr length:  774\n",
      "TRUE CORRECT:  9123\n",
      "Train Epoch: 2 [0/34496 (0%)]\tLoss: 0.051061\n",
      "Train Epoch: 2 [1280/34496 (4%)]\tLoss: 0.072603\n",
      "Train Epoch: 2 [2560/34496 (7%)]\tLoss: 0.028564\n",
      "Train Epoch: 2 [3840/34496 (11%)]\tLoss: 0.023886\n",
      "Train Epoch: 2 [5120/34496 (15%)]\tLoss: 0.030900\n",
      "Train Epoch: 2 [6400/34496 (19%)]\tLoss: 0.017856\n",
      "Train Epoch: 2 [7680/34496 (22%)]\tLoss: 0.015573\n",
      "Train Epoch: 2 [8960/34496 (26%)]\tLoss: 0.024864\n",
      "Train Epoch: 2 [10240/34496 (30%)]\tLoss: 0.089573\n",
      "Train Epoch: 2 [11520/34496 (33%)]\tLoss: 0.037460\n",
      "Train Epoch: 2 [12800/34496 (37%)]\tLoss: 0.029901\n",
      "Train Epoch: 2 [14080/34496 (41%)]\tLoss: 0.019879\n",
      "Train Epoch: 2 [15360/34496 (44%)]\tLoss: 0.039168\n",
      "Train Epoch: 2 [16640/34496 (48%)]\tLoss: 0.065410\n",
      "Train Epoch: 2 [17920/34496 (52%)]\tLoss: 0.057610\n",
      "Train Epoch: 2 [19200/34496 (56%)]\tLoss: 0.033108\n",
      "Train Epoch: 2 [20480/34496 (59%)]\tLoss: 0.017286\n",
      "Train Epoch: 2 [21760/34496 (63%)]\tLoss: 0.029355\n",
      "Train Epoch: 2 [23040/34496 (67%)]\tLoss: 0.134807\n",
      "Train Epoch: 2 [24320/34496 (70%)]\tLoss: 0.040810\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 539\u001b[0m\n\u001b[1;32m    533\u001b[0m             torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mstate_dict(), fileName)\n\u001b[1;32m    538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 539\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[2], line 527\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    525\u001b[0m scheduler \u001b[39m=\u001b[39m StepLR(optimizer, step_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, gamma\u001b[39m=\u001b[39mgamma)\n\u001b[1;32m    526\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m--> 527\u001b[0m     train(model, device, train_loader, optimizer, epoch, log_interval, dry_run)\n\u001b[1;32m    528\u001b[0m     test(model, device, test_loader, test_batch_size)\n\u001b[1;32m    529\u001b[0m     scheduler\u001b[39m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[2], line 58\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch, log_interval, dry_run)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# we aren't using `TripletLoss` as the MNIST dataset is simple, so `BCELoss` can do the trick.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mBCELoss()\n\u001b[0;32m---> 58\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (images_1, images_2, targets, _, _) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m     59\u001b[0m     images_1, images_2, targets \u001b[39m=\u001b[39m images_1\u001b[39m.\u001b[39mto(device), images_2\u001b[39m.\u001b[39mto(device), targets\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     60\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/fingerprint_new/lib/python3.9/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/fingerprint_new/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1330\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1329\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1330\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1331\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1332\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1333\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fingerprint_new/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1286\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1284\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m   1285\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[0;32m-> 1286\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1287\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1288\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/fingerprint_new/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1134\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1122\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1135\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1136\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1137\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fingerprint_new/lib/python3.9/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[39mif\u001b[39;00m remaining \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait(remaining)\n\u001b[1;32m    181\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_full\u001b[39m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/anaconda3/envs/fingerprint_new/lib/python3.9/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[1;32m    317\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Given Data Loader in Siamese_Sample folder\n",
    "# Train Libraries\n",
    "from __future__ import print_function\n",
    "import argparse, random, copy\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as T\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "# from dataloader import train_test_split, FingerprintDataset, ImageTransform\n",
    "# from model import SiameseNetwork\n",
    "import json\n",
    "\n",
    "\n",
    "# Model Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "\n",
    "# Dataloader libraries\n",
    "import os\n",
    "import random\n",
    "import albumentations\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_dist = F.pairwise_distance(output1, output2, keepdim=True)\n",
    "\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_dist, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_dist, min=0.0), 2))\n",
    "        return loss_contrastive\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval, dry_run):\n",
    "    model.train()\n",
    "\n",
    "    # we aren't using `TripletLoss` as the MNIST dataset is simple, so `BCELoss` can do the trick.\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    for batch_idx, (images_1, images_2, targets, _, _) in enumerate(train_loader):\n",
    "        images_1, images_2, targets = images_1.to(device), images_2.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images_1, images_2).squeeze()\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(images_1), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            if dry_run:\n",
    "                break\n",
    "\n",
    "def test(model, device, test_loader, test_batch_size):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    tot_correct = 0\n",
    "\n",
    "    true_correct = 0\n",
    "\n",
    "    tot_test_easy = 0\n",
    "    correct_test_easy = 0\n",
    "\n",
    "    tot_test_med = 0\n",
    "    correct_test_med = 0\n",
    "\n",
    "    tot_test_hard = 0\n",
    "    correct_test_hard = 0\n",
    "\n",
    "\n",
    "\n",
    "    # we aren't using `TripletLoss` as the MNIST dataset is simple, so `BCELoss` can do the trick.\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (images_1, images_2, targets, _, altered_addr) in test_loader:\n",
    "            images_1, images_2, targets = images_1.to(device), images_2.to(device), targets.to(device)\n",
    "            outputs = model(images_1, images_2).squeeze() \n",
    "            test_loss += criterion(outputs, targets).sum().item()  # sum up batch loss\n",
    "            ones = torch.ones(outputs.shape[0],).to(device)\n",
    "            zeros = torch.zeros(outputs.shape[0],).to(device)\n",
    "            pred = torch.where(outputs > 0.5, ones, zeros)  # get the index of the max log-probability\n",
    "            correctPred = pred.eq(targets.view_as(pred)).sum().item()\n",
    "            true_correct += correctPred\n",
    "            print(\"alteredaddr length: \", len(altered_addr))\n",
    "            for i in range(len(altered_addr)):\n",
    "            # print(\"correctPred:\", correctPred)\n",
    "                print(\"prediction and targets\", pred[i], targets[i])\n",
    "                print(\"alteredaddr\", altered_addr[i])\n",
    "                if \"Easy\" in altered_addr[i]:\n",
    "                    # print(\"EASY\")\n",
    "                    tot_test_easy+=1\n",
    "                    if pred[i]==targets[i]:\n",
    "                        correct_test_easy+=1\n",
    "                        tot_correct+=1\n",
    "\n",
    "                elif \"Medium\" in altered_addr[i]:\n",
    "                    # print(\"MEDIUM\")\n",
    "                    tot_test_med+=1\n",
    "                    if pred[i]==targets[i]:\n",
    "                        correct_test_med+=1\n",
    "                        tot_correct+=1\n",
    "\n",
    "                elif \"Hard\" in altered_addr[i]:\n",
    "                    # print(\"HARD\")\n",
    "                    tot_test_hard+=1\n",
    "                    if pred[i]==targets[i]:\n",
    "                        correct_test_hard+=1\n",
    "                        tot_correct+=1\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    # for the 1st epoch, the average loss is 0.0001 and the accuracy 97-98%\n",
    "    # using default settings. After completing the 10th epoch, the average\n",
    "    # loss is 0.0000 and the accuracy 99.5-100% using default settings.\n",
    "    print(\"TRUE CORRECT: \", true_correct)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Total Accuracy: {}/{} ({:.0f})%, Easy Accuracy: {}/{} ({:.0f})%, Medium Accuracy: {}/{} ({:.0f})%, Hard Accuracy: {}/{} ({:.0f})%)\\n'.format(\n",
    "        test_loss, tot_correct, len(test_loader.dataset), 100. * tot_correct / len(test_loader.dataset), \n",
    "        correct_test_easy, tot_test_easy, 100 * correct_test_easy / tot_test_easy,\n",
    "        correct_test_med, tot_test_med, 100 * correct_test_med / tot_test_med,\n",
    "        correct_test_hard, tot_test_hard, 100 * correct_test_hard / tot_test_hard,\n",
    "        ))\n",
    "# class SiameseNetwork(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SiameseNetwork, self).__init__()\n",
    "\n",
    "#         # convolutional neural network\n",
    "#         self.cnn1 = nn.Sequential(\n",
    "#             nn.Conv2d(1, 96, kernel_size=11, stride=4),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(3, stride=2),\n",
    "\n",
    "#             nn.Conv2d(96, 256, kernel_size=5, stride=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "#             nn.Conv2d(256, 384, kernel_size=3, stride=1),\n",
    "#             nn.ReLU(inplace=True)\n",
    "#         )\n",
    "\n",
    "#         # fully connected layers\n",
    "#         self.fc1 = nn.Sequential(\n",
    "#             nn.Linear(384, 1024),\n",
    "#             nn.ReLU(inplace=True),\n",
    "\n",
    "#             nn.Linear(1024, 256), \n",
    "#             nn.ReLU(inplace=True),\n",
    "\n",
    "#             nn.Linear(256, 2)\n",
    "#         )\n",
    "    \n",
    "#     def forward_once(self, x):\n",
    "#         output = self.cnn1(x)\n",
    "#         output = output.view(output.size()[0], -1)\n",
    "#         output = self.fc1(output)\n",
    "#         return output\n",
    "    \n",
    "#     def forward(self, input1, input2):\n",
    "#         output1 = self.forward_once(input1)\n",
    "#         output2 = self.forward_once(input2)\n",
    "#         output = torch.cat((output1, output2), 1)\n",
    "\n",
    "#         return output\n",
    "## GIVEN CODE for SIAMESE NETWORK\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "        Siamese network for image similarity estimation.\n",
    "        The network is composed of two identical networks, one for each input.\n",
    "        The output of each network is concatenated and passed to a linear layer. \n",
    "        The output of the linear layer passed through a sigmoid function.\n",
    "        `\"FaceNet\" <https://arxiv.org/pdf/1503.03832.pdf>`_ is a variant of the Siamese network.\n",
    "        This implementation varies from FaceNet as we use the `ResNet-18` model from\n",
    "        `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_ as our feature extractor.\n",
    "        In addition, we aren't using `TripletLoss` as the MNIST dataset is simple, so `BCELoss` can do the trick.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        # get resnet model\n",
    "        self.resnet = torchvision.models.resnet18(pretrained=False)\n",
    "\n",
    "        # over-write the first conv layer to be able to read MNIST images\n",
    "        # as resnet18 reads (3,x,x) where 3 is RGB channels\n",
    "        # whereas MNIST has (1,x,x) where 1 is a gray-scale channel\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.fc_in_features = self.resnet.fc.in_features\n",
    "        \n",
    "        # remove the last layer of resnet18 (linear layer which is before avgpool layer)\n",
    "        self.resnet = torch.nn.Sequential(*(list(self.resnet.children())[:-1]))\n",
    "        # print(self.resnet)\n",
    "\n",
    "        # add linear layers to compare between the features of the two images\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.fc_in_features * 2, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # initialize the weights\n",
    "        self.resnet.apply(self.init_weights)\n",
    "        self.fc.apply(self.init_weights)\n",
    "        \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        output = self.resnet(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # get two images' features\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "\n",
    "        # concatenate both images' features\n",
    "        output = torch.cat((output1, output2), 1)\n",
    "\n",
    "        # pass the concatenation to the linear layers\n",
    "        output = self.fc(output)\n",
    "\n",
    "        # pass the out of the linear layers to sigmoid layer\n",
    "        output = self.sigmoid(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "\n",
    "\n",
    "def train_test_split(base_dir, train_ratio, num_people = 600, randomize = True, tests = None):\n",
    "\n",
    "  # Splitting the train & test data according to the 'train_ratio' (ex. 0.9 : 0.1) \n",
    "  train_size = num_people * train_ratio\n",
    "  test_size = num_people - train_size\n",
    "\n",
    "  # Setting train_nums to be a list composed of 1 ~ 600\n",
    "  train_nums = [i+1 for i in range(0,num_people)]\n",
    "  # Setting test_nums to be a list composed of 600 zeros ([0,0,.....,0])\n",
    "  test_nums = [0 for i in range(0, num_people)]\n",
    "\n",
    "  train_list = []\n",
    "  test_list = []\n",
    "\n",
    "  altered_root = os.path.join(base_dir, \"Altered\")\n",
    "  altered_list = [\"Altered-Easy\", \"Altered-Medium\", \"Altered-Hard\"]\n",
    "\n",
    "  test_check = []\n",
    "\n",
    "  # Randomly select people who will be used as test subjects\n",
    "  if randomize :\n",
    "    while len(test_check) < test_size:\n",
    "      test = random.randint(1,num_people)\n",
    "      if test not in test_check :\n",
    "        test_check.append(test)\n",
    "        test_nums[test-1] = test\n",
    "    \n",
    "    for i in range(0, len(train_nums)):\n",
    "      train_nums[i] = train_nums[i]-test_nums[i]\n",
    "\n",
    "    train_nums = set(train_nums)\n",
    "    train_nums.remove(0)\n",
    "    train_nums = list(train_nums)\n",
    "\n",
    "    test_nums = set(test_nums)\n",
    "    test_nums.remove(0)\n",
    "    test_nums = list(test_nums)\n",
    "\n",
    "    print(\"Num Train Data : \",len(train_nums))\n",
    "    print(\"Num Test Data : \", len(test_nums))\n",
    "  # If we pre-select test subjects, then just remove these from the train subjects\n",
    "  # train subjects will initially contain all individuals (1 ~ 600)\n",
    "  else :\n",
    "    test_nums = tests\n",
    "    for i in range(0, len(test_nums)):\n",
    "      if test_nums[i] in train_nums:\n",
    "        train_nums.remove(test_nums[i])\n",
    "  \n",
    "  # Let's go through the altered images and organize them depending on \n",
    "  # whether they can be used for training or testing of the model\n",
    "  for altered in altered_list : \n",
    "    altered_dir = os.path.join(altered_root, altered)\n",
    "    altered_imgs = os.listdir(altered_dir)\n",
    "    \n",
    "    for img in altered_imgs :\n",
    "      person_num = int(img[:img.find('__')])\n",
    "      if person_num in test_nums :\n",
    "        test_img_path = os.path.join(altered_dir, img)\n",
    "        test_list.append(test_img_path)\n",
    "      else:\n",
    "        train_img_path = os.path.join(altered_dir, img)\n",
    "        train_list.append(train_img_path)\n",
    "\n",
    "  # train_list & test_list are made of altered images\n",
    "  return train_nums, train_list, test_nums, test_list\n",
    "\n",
    "class ImageTransform():\n",
    "  def __init__(self, mean, std):\n",
    "    self.data_transform = transforms.Compose([\n",
    "        transforms.Resize((100, 100)),\n",
    "        # transforms.Resize((95, 95)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ])\n",
    "\n",
    "  def __call__(self, img):\n",
    "    # print(type(img))\n",
    "    return self.data_transform(img)\n",
    "      \n",
    "class ImageAugTransform_train():\n",
    "  def __init__(self, mean, std):\n",
    "    self.albumentations_transform_oneof = albumentations.Compose([\n",
    "                                                                  albumentations.Resize(100, 100),\n",
    "                                                                  albumentations.Normalize(mean=mean, std=std, max_pixel_value=255),\n",
    "                                                                  albumentations.OneOf([\n",
    "                                                                                        albumentations.HorizontalFlip(p=0.5),\n",
    "                                                                                        albumentations.RandomRotate90(p=0.5)\n",
    "                                                                                        ], p=0.5),\n",
    "                                                                  albumentations.OneOf([\n",
    "                                                                  albumentations.GaussNoise(p=0.5)\n",
    "                                                                  ], p=0.5),\n",
    "                                                                  albumentations.RandomBrightness(limit=0.2, always_apply=False, p=0.5)\n",
    "                                                                  ])\n",
    "\n",
    "  def __call__(self, img):\n",
    "      return self.albumentations_transform_oneof(image=img)\n",
    "\n",
    "# The FingerPrintDataset used to load into pytorch dataloader\n",
    "class FingerprintDataset(Dataset):\n",
    "  def __init__(self, data_nums, data_list, transform=None, transAug=None):\n",
    "    self.data_nums = data_nums\n",
    "    self.data_list = data_list\n",
    "    self.transform = transform\n",
    "    self.transAug = transAug\n",
    "    \n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "  \n",
    "    real_dir = '../../SOCOFingBMP/Real'\n",
    "    real_imgs = os.listdir(real_dir)\n",
    "\n",
    "    # img will be a case from altered image\n",
    "    img = self.data_list[idx]\n",
    "    # find a corresponding name that can be used for identifying the real image\n",
    "    img_name_real = img[img.rfind('/')+1:img.rfind('_')] + '.BMP'\n",
    "    \n",
    "    # This will set probability for creating matching or non-matching case at 50%\n",
    "    print_match = idx % 2 == 0\n",
    "\n",
    "    # This will set probability for applying augmentation at 50%\n",
    "    apply_aug = random.randint(0,1)\n",
    "    \n",
    "    # print_match : 0 means non-matching fingerprints\n",
    "    # print_match : 1 means matching fingerprints\n",
    "    if print_match : # Define the directory for which we will find the matching real case (same individual)\n",
    "      real_img_dir = os.path.join(real_dir, img_name_real)\n",
    "    else :\n",
    "      while True: # Define the directory for which we will find the non-matching real case (different individual)\n",
    "        real_img_num = random.choice(self.data_nums)-1 \n",
    "        img_name_real_unmatch = real_imgs[real_img_num]\n",
    "        \n",
    "        if img_name_real != img_name_real_unmatch:\n",
    "          real_img_dir = os.path.join(real_dir, img_name_real_unmatch)\n",
    "          break\n",
    "\n",
    "    real_directory = real_img_dir\n",
    "    # print(real_directory)\n",
    "    altered_directory = img\n",
    "    # print(altered_directory)\n",
    "    real = Image.open(real_img_dir).convert(\"L\")\n",
    "    altered = Image.open(img).convert(\"L\")\n",
    "    \n",
    "    real = self.transform(real)\n",
    "\n",
    "    if self.transAug is None :\n",
    "      altered = self.transform(altered)\n",
    "    else : \n",
    "      if apply_aug :\n",
    "        altered_np = np.array(altered)\n",
    "        altered_augmented = self.transAug(altered_np)\n",
    "        altered = Image.fromarray(altered_augmented['image'])\n",
    "        altered = self.transform(altered)\n",
    "      else : \n",
    "        altered = self.transform(altered)\n",
    "    \n",
    "    # label = torch.from_numpy(np.array([int(print_match)], dtype=np.long))\n",
    "    label = torch.tensor(print_match, dtype=torch.float)\n",
    "    # label = print_match\n",
    "    # pairset = {\"real\": real, \"altered\": altered, \"label\": torch.from_numpy(np.array([int(print_match)], dtype=np.float32))}\n",
    "    \n",
    "    # return pairset\n",
    "    return real, altered, label, real_directory, altered_directory\n",
    "\n",
    "  def __len__(self):\n",
    "    length = len(self.data_list)\n",
    "    return length\n",
    "from datetime import datetime\n",
    "def makedir(path):\n",
    "\tif not os.path.exists(path):\n",
    "\t\tos.makedirs(path)\n",
    "\n",
    "# logs the model you used into a text file. \n",
    "# More than welcome to modify this function to keep track of the results\n",
    "def log():\n",
    "    with open('all_levels_newDataloader.ipynb', 'r') as inputfile:\n",
    "        textstr = inputfile.read()\n",
    "        fn = datetime.now().strftime('%Y_%m_%d_%H_%M_%S') + \".txt\"\n",
    "        log_path = \"./logs/\"\n",
    "        makedir(log_path)\n",
    "        with open(log_path + fn, 'w') as outputfile:\n",
    "            outputfile.write(textstr)\n",
    "        return fn\n",
    "def main():\n",
    "    fn = log()\n",
    "    # Training settings\n",
    "    # parser = argparse.ArgumentParser(description='PyTorch Siamese network Example')\n",
    "    # parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "    #                     help='input batch size for training (default: 64)')\n",
    "    batch_size = 128\n",
    "    # parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "    #                     help='input batch size for testing (default: 1000)')\n",
    "    test_batch_size = 1000\n",
    "    # parser.add_argument('--epochs', type=int, default=14, metavar='N',\n",
    "    #                     help='number of epochs to train (default: 14)')\n",
    "    epochs = 6\n",
    "    # parser.add_argument('--lr', type=float, default=1.0, metavar='LR',\n",
    "    #                     help='learning rate (default: 1.0)')\n",
    "    lr = 0.1\n",
    "    # parser.add_argument('--gamma', type=float, default=0.7, metavar='M',\n",
    "    #                     help='Learning rate step gamma (default: 0.7)')\n",
    "    gamma = 0.7\n",
    "    # parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "    #                     help='disables CUDA training')\n",
    "    no_cuda = False\n",
    "    # parser.add_argument('--no-mps', action='store_true', default=False,\n",
    "    #                     help='disables macOS GPU training')\n",
    "    no_mps = False\n",
    "    # parser.add_argument('--dry-run', action='store_true', default=False,\n",
    "    #                     help='quickly check a single pass')\n",
    "    dry_run = False\n",
    "    # parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "    #                     help='random seed (default: 1)')\n",
    "    seed = 1\n",
    "    # parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "    #                     help='how many batches to wait before logging training status')\n",
    "    log_interval = 10\n",
    "    # parser.add_argument('--save-model', action='store_true', default=False,\n",
    "    #                     help='For Saving the current Model')\n",
    "    save_model = True\n",
    "    # args = parser.parse_args()\n",
    "    \n",
    "    use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    train_kwargs = {'batch_size': batch_size}\n",
    "    test_kwargs = {'batch_size': test_batch_size}\n",
    "    if use_cuda:\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "\n",
    "    mean = (0.5,) #q1\n",
    "    std = (0.5,)\n",
    "\n",
    "    # Change the directory to where SOCOFing is located. \n",
    "    # Direcotories should look as the following\n",
    "    # SOCOFing\n",
    "    # -- Altered\n",
    "    #    -- ...\n",
    "    # -- Real\n",
    "    #    -- ...\n",
    "    base_dir = '../../SOCOFingBMP/'\n",
    "\n",
    "    nums = {}\n",
    "    train_nums, train_list, test_nums, test_list = train_test_split(base_dir, 0.7)\n",
    "    print(\"Train List Length : \", len(train_list))\n",
    "    print(\"Test List Length : \", len(test_list))\n",
    "\n",
    "    nums['train'] = train_nums\n",
    "    nums['test'] = test_nums\n",
    "    \n",
    "    # state_dict save file name : siamese_network_train%_test%_lr.pt\n",
    "    outpath = 'train_test_split_{fn}.json'\n",
    "\n",
    "    with open(outpath, 'w') as f:\n",
    "        json.dump(nums, f)\n",
    "\n",
    "\n",
    "    train_dataset = FingerprintDataset(train_nums, train_list, transform=ImageTransform(mean,std), transAug=None)\n",
    "    test_dataset = FingerprintDataset(test_nums, test_list, transform=ImageTransform(mean,std))\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,**train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, **test_kwargs)\n",
    "\n",
    "    model = SiameseNetwork().to(device)\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
    "    # optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum = 0.9, weight_decay = 1e-6) \n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch, log_interval, dry_run)\n",
    "        test(model, device, test_loader, test_batch_size)\n",
    "        scheduler.step()\n",
    "        if epoch % 5==0 and save_model:\n",
    "            # state_dict save file name : siamese_network_train%_test%_lr.pt\n",
    "            fileName = str(f'Siamese_network_Date:{fn}__Epoch:{epoch}.pt')\n",
    "            torch.save(model.state_dict(), fileName)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fingerprint_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
